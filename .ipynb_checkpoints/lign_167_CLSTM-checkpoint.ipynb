{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import numpy as np\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "10000\n",
      "40000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#load data and labels \n",
    "\n",
    "with open('train_tweet_embeddings.pkl', 'rb') as f:\n",
    "    train_sentence_embeddings_list = pickle.load(f)\n",
    "print(len(train_sentence_embeddings_list))\n",
    "\n",
    "with open('test_tweet_embeddings.pkl', 'rb') as f:\n",
    "    test_sentence_embeddings_list = pickle.load(f)\n",
    "print(len(test_sentence_embeddings_list))\n",
    "\n",
    "\n",
    "with open('train_labels.pkl', 'rb') as f:\n",
    "    train_labels = pickle.load(f)\n",
    "print(len(train_labels))\n",
    "\n",
    "with open('test_labels.pkl', 'rb') as f:\n",
    "    test_labels = pickle.load(f)\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLSTM(\n",
      "  (conv1): Conv1d(1, 20, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "  (conv2): Conv1d(20, 10, kernel_size=(5,), stride=(2,), padding=(2,))\n",
      "  (lstm): LSTM(48, 48, num_layers=2, bidirectional=True)\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=40, bias=True)\n",
      "  (fc3): Linear(in_features=40, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Definition of the model\n",
    "\n",
    "class CLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLSTM,self).__init__()\n",
    "        # expects input tensor of [1,1,768]\n",
    "        # 1 input channel, 20 output channels, 1x5 convolution with padding\n",
    "        self.conv1 = nn.Conv1d(1,20,5,stride = 2,padding = 2)\n",
    "        # 20 input channel, 10 output channels, 1x5 convolution\n",
    "        self.conv2 = nn.Conv1d(20,10,5,stride = 2,padding = 2)\n",
    "        # end up with tensors [1,10,192]\n",
    "        # these turn into tensors [1,10,48] after pooling which we will\n",
    "        # these are turned into a list of 10 [1,48] tensors to pass into the lstm\n",
    "        # each of these 10 will be taken in as token representations\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = 48,hidden_size = 48,num_layers = 2,bidirectional = True)\n",
    "        # the lstm will output tuple of ([4,1,48],[4,1,48]) where the first entry is\n",
    "        # the hidden state for classification and the second entry is the cell state\n",
    "\n",
    "        self.fc1 = nn.Linear(4*48,120)\n",
    "        self.fc2 = nn.Linear(120,40)\n",
    "        self.fc3 = nn.Linear(40,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #set initial hidden state and cell state for lstm\n",
    "        # 2 is for the number of layers and the other 2 is because of bidirection\n",
    "        hidden = torch.randn(2*2,1,48)\n",
    "        cell = torch.randn(2*2,1,48)\n",
    "        \n",
    "        x = F.max_pool1d(F.relu(self.conv1(x)),kernel_size = 2,stride = 2)\n",
    "        x = F.max_pool1d(F.relu(self.conv2(x)),kernel_size = 2,stride = 2)\n",
    "        # x is now a tensor of shape [1,10,48] because we did the pooling\n",
    "        \n",
    "        # now put the \"tokens\" into a list\n",
    "        tweet_representation = []\n",
    "        for i in range(len(x[0])):\n",
    "            tweet_representation.append(x[0][i].unsqueeze(0))\n",
    "        # tweet_representation is a list of the ten [1,48] tensors to\n",
    "        # be passed into the lstm\n",
    "        for j in tweet_representation:\n",
    "            _, hidden_tuple = self.lstm(j.view(1,1,-1),(hidden,cell)) \n",
    "\n",
    "        # hidden state tensor [4,1,48]\n",
    "        hidden_state = hidden_tuple[0]\n",
    "        # flatten the hidden_state to tensor [192]\n",
    "        x = hidden_state.reshape(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x is now 1 x 120\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x is now 1 x 30\n",
    "        x = self.fc3(x)\n",
    "        # x is now a single predicted class\n",
    "        return torch.sigmoid(x)\n",
    "model = CLSTM()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5042], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# small test of the model---------------\n",
    "input = torch.randn(1,1,768)\n",
    "out = model(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40000, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell formats the input data\n",
    "train_data = torch.stack(train_sentence_embeddings_list)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/40000], Loss: 0.6646\n",
      "Epoch [1/2], Step [200/40000], Loss: 0.6135\n",
      "Epoch [1/2], Step [300/40000], Loss: 0.5444\n",
      "Epoch [1/2], Step [400/40000], Loss: 0.5019\n",
      "Epoch [1/2], Step [500/40000], Loss: 0.5556\n",
      "Epoch [1/2], Step [600/40000], Loss: 0.5741\n",
      "Epoch [1/2], Step [700/40000], Loss: 0.5499\n",
      "Epoch [1/2], Step [800/40000], Loss: 0.5623\n",
      "Epoch [1/2], Step [900/40000], Loss: 0.5455\n",
      "Epoch [1/2], Step [1000/40000], Loss: 0.5723\n",
      "Epoch [1/2], Step [1100/40000], Loss: 0.5177\n",
      "Epoch [1/2], Step [1200/40000], Loss: 0.5136\n",
      "Epoch [1/2], Step [1300/40000], Loss: 0.5264\n",
      "Epoch [1/2], Step [1400/40000], Loss: 0.5591\n",
      "Epoch [1/2], Step [1500/40000], Loss: 0.5272\n",
      "Epoch [1/2], Step [1600/40000], Loss: 0.5974\n",
      "Epoch [1/2], Step [1700/40000], Loss: 0.5373\n",
      "Epoch [1/2], Step [1800/40000], Loss: 1.0309\n",
      "Epoch [1/2], Step [1900/40000], Loss: 0.5066\n",
      "Epoch [1/2], Step [2000/40000], Loss: 0.4755\n",
      "Epoch [1/2], Step [2100/40000], Loss: 0.9405\n",
      "Epoch [1/2], Step [2200/40000], Loss: 0.9172\n",
      "Epoch [1/2], Step [2300/40000], Loss: 0.8616\n",
      "Epoch [1/2], Step [2400/40000], Loss: 0.9665\n",
      "Epoch [1/2], Step [2500/40000], Loss: 0.9630\n",
      "Epoch [1/2], Step [2600/40000], Loss: 0.4769\n",
      "Epoch [1/2], Step [2700/40000], Loss: 0.5072\n",
      "Epoch [1/2], Step [2800/40000], Loss: 0.9595\n",
      "Epoch [1/2], Step [2900/40000], Loss: 0.8770\n",
      "Epoch [1/2], Step [3000/40000], Loss: 0.9110\n",
      "Epoch [1/2], Step [3100/40000], Loss: 0.9369\n",
      "Epoch [1/2], Step [3200/40000], Loss: 0.9224\n",
      "Epoch [1/2], Step [3300/40000], Loss: 0.4990\n",
      "Epoch [1/2], Step [3400/40000], Loss: 0.4886\n",
      "Epoch [1/2], Step [3500/40000], Loss: 0.9950\n",
      "Epoch [1/2], Step [3600/40000], Loss: 0.4488\n",
      "Epoch [1/2], Step [3700/40000], Loss: 0.4481\n",
      "Epoch [1/2], Step [3800/40000], Loss: 0.5037\n",
      "Epoch [1/2], Step [3900/40000], Loss: 0.5175\n",
      "Epoch [1/2], Step [4000/40000], Loss: 0.4989\n",
      "Epoch [1/2], Step [4100/40000], Loss: 0.5163\n",
      "Epoch [1/2], Step [4200/40000], Loss: 0.9310\n",
      "Epoch [1/2], Step [4300/40000], Loss: 0.9421\n",
      "Epoch [1/2], Step [4400/40000], Loss: 0.5346\n",
      "Epoch [1/2], Step [4500/40000], Loss: 0.5174\n",
      "Epoch [1/2], Step [4600/40000], Loss: 0.9623\n",
      "Epoch [1/2], Step [4700/40000], Loss: 0.9122\n",
      "Epoch [1/2], Step [4800/40000], Loss: 0.5070\n",
      "Epoch [1/2], Step [4900/40000], Loss: 0.5510\n",
      "Epoch [1/2], Step [5000/40000], Loss: 0.5563\n",
      "Epoch [1/2], Step [5100/40000], Loss: 0.5169\n",
      "Epoch [1/2], Step [5200/40000], Loss: 0.9217\n",
      "Epoch [1/2], Step [5300/40000], Loss: 0.5631\n",
      "Epoch [1/2], Step [5400/40000], Loss: 0.5137\n",
      "Epoch [1/2], Step [5500/40000], Loss: 0.5172\n",
      "Epoch [1/2], Step [5600/40000], Loss: 0.5410\n",
      "Epoch [1/2], Step [5700/40000], Loss: 0.4687\n",
      "Epoch [1/2], Step [5800/40000], Loss: 0.4766\n",
      "Epoch [1/2], Step [5900/40000], Loss: 0.4897\n",
      "Epoch [1/2], Step [6000/40000], Loss: 0.5478\n",
      "Epoch [1/2], Step [6100/40000], Loss: 0.5453\n",
      "Epoch [1/2], Step [6200/40000], Loss: 0.8571\n",
      "Epoch [1/2], Step [6300/40000], Loss: 0.9399\n",
      "Epoch [1/2], Step [6400/40000], Loss: 0.9337\n",
      "Epoch [1/2], Step [6500/40000], Loss: 0.4697\n",
      "Epoch [1/2], Step [6600/40000], Loss: 0.4538\n",
      "Epoch [1/2], Step [6700/40000], Loss: 1.0243\n",
      "Epoch [1/2], Step [6800/40000], Loss: 0.4751\n",
      "Epoch [1/2], Step [6900/40000], Loss: 0.4945\n",
      "Epoch [1/2], Step [7000/40000], Loss: 0.4711\n",
      "Epoch [1/2], Step [7100/40000], Loss: 0.4545\n",
      "Epoch [1/2], Step [7200/40000], Loss: 1.0026\n",
      "Epoch [1/2], Step [7300/40000], Loss: 0.4998\n",
      "Epoch [1/2], Step [7400/40000], Loss: 0.8865\n",
      "Epoch [1/2], Step [7500/40000], Loss: 0.5275\n",
      "Epoch [1/2], Step [7600/40000], Loss: 0.8776\n",
      "Epoch [1/2], Step [7700/40000], Loss: 0.4736\n",
      "Epoch [1/2], Step [7800/40000], Loss: 1.0054\n",
      "Epoch [1/2], Step [7900/40000], Loss: 0.9522\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a36a3657e4c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1d864df6918e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# be passed into the lstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet_representation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# hidden state tensor [4,1,48]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    525\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    526\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = .01)\n",
    "\n",
    "#10 is the number of epochs\n",
    "total_step = len(train_data)\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_data,0):\n",
    "        #inputs.shape is [1,1,768]\n",
    "        inputs = data\n",
    "        #label is int (1 or 0)\n",
    "        label = train_labels[i]\n",
    "        label = torch.tensor([float(label)])\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.unsqueeze(0).unsqueeze(0)\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print stats\n",
    "        running_loss +=loss.item()\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, 100, i+1, total_step, loss.item()))\n",
    "            running_loss = 0.0\n",
    "print('finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
